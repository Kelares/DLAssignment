{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a CNN for CIFAR-10 Classification with Regularization Strategies\n",
    "\n",
    "This notebook focuses on the implementation of a Convolutional Neural Network (CNN) for the classification of the CIFAR-10 dataset. The primary goal is to build a robust model capable of accurately classifying images from the CIFAR-10 dataset, which consists of 32x32 color images in 10 different classes. In addition to the CNN architecture, the notebook explores regularization strategies to mitigate overfitting, a common challenge in deep learning. Regularization techniques such as dropout and data augmentation will be incorporated to enhance the model's generalization performance and prevent it from memorizing the training data excessively. Through step-by-step code implementation and analysis, this notebook aims to provide a comprehensive understanding of building CNN models for image classification tasks, emphasizing the importance of regularization in improving model performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necesary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import seaborn as sns\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Check if GPU is available and set device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device set to: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading and Balanced Subset Creation\n",
    "\n",
    "The following code defines a function, `get_data_loaders`, to load and preprocess the CIFAR-10 dataset, creating balanced subsets for training, validation, and testing. We only use a subset of CIFAR for testing different models and regularization strategies on a smaller dataset.\n",
    "\n",
    "## PyTorch Dataset\n",
    "In PyTorch, a Dataset is an abstract class that provides an interface for accessing and loading data. It is a crucial component of PyTorchâ€™s torch.utils.data module and is typically used to handle large datasets efficiently.\n",
    "A Dataset in PyTorch:\n",
    "Represents a collection of data (e.g., images, text, or tabular data).\n",
    "Implements the __getitem__() method to retrieve individual data points.\n",
    "Implements the __len__() method to return the total number of samples.\n",
    "Can be used with DataLoader for efficient batching and shuffling.\n",
    "\n",
    "## PyTorch DataLoader\n",
    "The DataLoader in PyTorch is a utility that efficiently loads data from a Dataset, particularly when working with large datasets. It is part of the torch.utils.data module and is commonly used in deep learning pipelines to enable: \n",
    " - Batching: Loads multiple samples at once instead of one-by-one.\n",
    " - Shuffling: Randomizes data order to prevent model overfitting.\n",
    " - Parallel Data Loading: Uses multiple workers for faster data loading.\n",
    " - Automatic Collation: Combines samples into mini-batches.\n",
    "\n",
    "## Function Description\n",
    "\n",
    "The `get_data_loaders` function takes a pytorch transform instance (`transform_train`) and a batch size as parameters. It returns three data loaders for training, validation, and testing, along with the class names of CIFAR-10.\n",
    "\n",
    "1. **Data Transformation:**\n",
    "    - In PyTorch, a transform is a function or a set of operations applied to data (such as images, tensors, or other inputs) to preprocess or augment it before feeding it into a deep learning model.\n",
    "    - A basic data transformation is defined to convert images to tensors and normalize them, which is a necesary step when working with images.\n",
    "    - If a train_transform is given, then a new dataset with that transform for the train DataLoader is created. So the transform for images in the train set can be different to that in the validation and test sets.\n",
    "    - In Torchvision, which is a PyTorch package for image processing, transforms are used specifically for preprocessing and data augmentation of images, such as resizing, cropping, normalization, and converting images to tensors. We will make use of such functionality later when we include data augmentation in our training.\n",
    "    \n",
    "2. **Loading CIFAR-10 Dataset:**\n",
    "    - The full CIFAR-10 dataset is loaded with the basic defined transformation.\n",
    "    - If a specific transformation for training (`transform_train`) is provided, a new dataset with that transformation is created; otherwise, the original dataset is used for training.\n",
    "\n",
    "3. **Balanced Subset Creation:**\n",
    "    - A balanced subset is created to ensure equal representation of each class.\n",
    "    - Indices for each class are stored in a dictionary (`class_indices_dict`).\n",
    "    - The code iterates over the dataset, collecting indices for each class.\n",
    "\n",
    "4. **Splitting:**\n",
    "    - A balanced subset of indices is obtained by sampling an equal number of instances from each class.\n",
    "    - The indices are split into training, validation, and test sets.\n",
    "\n",
    "5. **Creating Subsets and Data Loaders:**\n",
    "    - Subsets are created using the `Subset` class from PyTorch.\n",
    "    - Data loaders are created for training, validation, and testing.\n",
    "\n",
    "6. **Return Values:**\n",
    "    - The function returns the data loaders for training, validation, and testing, along with the class names.\n",
    "\n",
    "### Creating Dataloaders\n",
    "\n",
    "To load the data, the `get_data_loaders` function is called with the training transformation and a batch size of 128. The resulting data loaders (`train_loader`, `val_loader`, `test_loader`), and class names (`class_names`) are obtained.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Get Data Loaders for CIFAR-10 Dataset\n",
    "\n",
    "# This function takes a transformation for training data and a batch size as input and returns train, validation, and test data loaders along with class names.\n",
    "\n",
    "def get_data_loaders(transform_train, batch_size=128):\n",
    "    # Create a transform to convert images to tensors and normalize them\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    # Load the full CIFAR10 dataset\n",
    "    dataset_ = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
    "\n",
    "    # If a train_transform is given, create a new dataset with that transform for the train DataLoader\n",
    "    if transform_train is None:\n",
    "        dataset_train = dataset_\n",
    "    else:\n",
    "        dataset_train = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform_train, download=True)\n",
    "\n",
    "    # Get the class names of CIFAR-10\n",
    "    class_names = dataset_.classes\n",
    "\n",
    "    # Define the size of the train, validation, and test sets\n",
    "    train_size = 5000\n",
    "    val_size = 1000\n",
    "    test_size = 1000\n",
    "    subset_size = train_size + val_size + test_size \n",
    "\n",
    "    # Create a balanced subset\n",
    "    # Use a dictionary to store indices for each class\n",
    "    # Initialize an empty dictionary, where keys are class indices and values are lists to store indices for each class.\n",
    "    class_indices_dict = {class_idx: [] for class_idx in range(len(class_names))}\n",
    "\n",
    "    # Iterate over the dataset to collect indices for each class\n",
    "    # Iterate through the dataset, extract the index `i` and label from each element, and append the index to the corresponding class in the dictionary.\n",
    "    for i, (_, label) in enumerate(dataset_):\n",
    "        class_indices_dict[label].append(i)\n",
    "\n",
    "    # Split the indices into training, validation, and test sets\n",
    "    train_indices = []\n",
    "    val_indices = []\n",
    "    test_indices = []\n",
    "\n",
    "    train_size_per_class = train_size // len(class_names)\n",
    "    val_size_per_class = val_size // len(class_names)\n",
    "    test_size_per_class = test_size // len(class_names)\n",
    "    for idx in range(len(class_names)):\n",
    "        indices = class_indices_dict[idx][:subset_size]\n",
    "        train_indices.extend(indices[:train_size_per_class])\n",
    "        val_indices.extend(indices[train_size_per_class:train_size_per_class + val_size_per_class])\n",
    "        test_indices.extend(indices[train_size_per_class + val_size_per_class:train_size_per_class + val_size_per_class + test_size_per_class])\n",
    "\n",
    "    # Create subsets\n",
    "    train_dataset = Subset(dataset_train, train_indices)\n",
    "    val_dataset = Subset(dataset_, val_indices)\n",
    "    test_dataset = Subset(dataset_, test_indices)\n",
    "\n",
    "    # Create data loader for the training set with WeightedRandomSampler\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    # Create data loader for the validation set\n",
    "    val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size)\n",
    "    # Create data loader for the test set\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size)\n",
    "\n",
    "    return train_loader, val_loader, test_loader, class_names\n",
    "\n",
    "# Load the data\n",
    "train_loader, val_loader, test_loader, class_names = get_data_loaders(None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the data\n",
    "\n",
    "Here, we can visualize a set of one sample image per class from the CIFAR-10 dataset. \n",
    "It utilizes a dictionary, class_samples, to store one image for each class. The code iterates through the training dataset using a DataLoader, extracting images and labels. For each image, if there is no sample image stored for its corresponding class in class_samples, it is stored. The loop breaks once at least one sample image for each class is found. Finally, the code visualizes these sampled images, presenting a grid of images with corresponding class labels. This process provides a representative glimpse of the variety present in the CIFAR-10 dataset across different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_data(class_names, data_loader):\n",
    "    # Create a dictionary to store one sample image per class\n",
    "    class_samples = {class_name: None for class_name in class_names}\n",
    "    # Find one sample image for each class\n",
    "    for images, labels in data_loader:\n",
    "        for image, label in zip(images, labels):\n",
    "            if class_samples[class_names[label]] is None:\n",
    "                class_samples[class_names[label]] = image\n",
    "                # Break once a sample is found for each class\n",
    "                if all(sample is not None for sample in class_samples.values()):\n",
    "                    break\n",
    "\n",
    "    # Visualize one sample from each class\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for i, (class_name, sample_image) in enumerate(class_samples.items()):\n",
    "        plt.subplot(2, 5, i + 1)\n",
    "        sample_image = sample_image.permute(1, 2, 0).numpy()  # Change from (C, H, W) to (H, W, C) for plotting\n",
    "        plt.imshow((sample_image + 1) / 2)  # Denormalize the image\n",
    "        plt.title(class_name)\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_data(class_names, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check if the classes are balanced in our test set. To do that, we create and plot a histogram of labels in the data by checking all the samples yielded by the dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract labels from the subset\n",
    "subset_labels = []\n",
    "\n",
    "for _, labels in train_loader:\n",
    "    # Assuming labels are a tensor, we convert them to a list and extend our accumulating list\n",
    "    subset_labels.extend(labels.tolist())\n",
    "\n",
    "# Plot histogram\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(subset_labels, bins=range(11), edgecolor='black', align='left', rwidth=0.8)\n",
    "plt.title('Histogram of Labels in the train set')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(range(10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple CNN Model Definition\n",
    "\n",
    "In this section, we define a simple Convolutional Neural Network (CNN) using PyTorch. The purpose of this model is to classify images from the CIFAR-10 dataset into one of the ten predefined classes. The model architecture consists of convolutional layers followed by max-pooling layers, and fully connected layers for classification. Let's break down the key components:\n",
    "\n",
    "## Model Architecture\n",
    "1. **Convolutional Layers:**\n",
    "   - `self.conv1`: The first convolutional layer takes the input (RGB images) and produces feature maps with 16 output channels. The kernel size is set to 3 and padding needs to be 1 to keep the input dimension.\n",
    "   - `self.conv2`: The second convolutional layer takes the output of the first after the activation funtion and pooling are applied and produces a feature map with 32 channels, and has the the same kernel size and padding (3 and 1).\n",
    "   - `self.conv3`: The third convolutional layer further increases the number of output channels to 64.\n",
    "\n",
    "2. **Activation and Pooling:**\n",
    "   - `self.relu`: Rectified Linear Unit (ReLU) activation function is applied after each convolutional layer to introduce non-linearity.\n",
    "   - `self.pool`: Max-pooling layer with a kernel size of 2 and a stride of 2 is used to downsample the spatial dimensions.\n",
    "\n",
    "3. **Fully Connected Layers:**\n",
    "   - `self.fc1`: The first fully connected layer takes the flattened output from the last convolutional layer and maps it to 64 units.\n",
    "   - `self.fc2`: The final fully connected layer maps the 64 units to the output space with 10 units, corresponding to the number of classes in CIFAR-10.\n",
    "\n",
    "## Forward Pass\n",
    "The `forward` method defines the forward pass of the model. It specifies how input data flows through the layers to produce the final output. Convolutional and pooling layers are followed by activation functions, and the fully connected layers provide the classification logits. Note that the same relu and pooling layers are used in several parts. That is ok as these layers do not have parameters and are only applying the same function to any input, so no separate layers are needed.\n",
    "\n",
    "This simple CNN serves as a starting point for image classification tasks and can be further customized or extended for more complex problems.\n",
    "\n",
    "# Task: Complete the CNN Model Definition\n",
    "\n",
    "Your task is to complete the implementation of the forward pass in the `forward` method of the Simple CNN model. The provided architecture includes convolutional layers, activation functions, and fully connected layers. Your goal is to specify the correct input channels and sizes for the linear layers. Follow the instructions below:\n",
    "\n",
    "### Convolutional Layers\n",
    "* `self.conv2`: **Make sure that the second convolutional layer produces a feature map with 32 channels, and has the same kernel size 3 and padding 1**.\n",
    "\n",
    "\n",
    "### Fully Connected Layers\n",
    "- `self.fc1`: The first fully connected layer takes the flattened output from the last convolutional layer and maps it to 64 units. **Specify the correct number of input and output features**. To do this, you need to calculate what would the output size of the last convolutional layer be, given that the input are images of size 32 by 32 pixels.\n",
    "\n",
    "Feel free to refer to the provided comments and model architecture for guidance. This task aims to reinforce your understanding of input dimensions in neural network layers. Once completed, you'll have a functional CNN model ready for training on the CIFAR-10 dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple CNN model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        # First Convolutional Layer\n",
    "        self.conv1 = nn.Conv2d(in_channels= 3 , out_channels=16, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Second Convolutional Layer\n",
    "        self.conv2 = ## YOUR CODE HERE ##\n",
    "        \n",
    "        # Third Convolutional Layer\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Fully Connected Layers\n",
    "        fc1_in_features = ## YOUR CODE HERE ##\n",
    "        fc1_out_features = ## YOUR CODE HERE ##\n",
    "        self.fc1 = nn.Linear(in_features=fc1_in_features, out_features=fc1_out_features)\n",
    "        self.fc2 = nn.Linear(in_features=64, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # First Convolutional Block\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        # Second Convolutional Block\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        # Third Convolutional Block\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        # Flatten for Fully Connected Layers\n",
    "        x = x.view(-1, self.fc1.in_features)\n",
    "        \n",
    "        # Fully Connected Layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop\n",
    "This code follows the same logic as all other trainng loops in previous notebooks for MLPs, so no much detail is given here.\n",
    "This code defines a training loop with validation for a PyTorch model. It iterates through epochs, performing training and validation steps, and tracks losses and accuracies. The training loop prints progress every 10 epochs and plots loss and accuracy curves. The model is set to training mode during the training loop and evaluation mode during validation to ensure proper behavior of layers like dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop with Validation\n",
    "def train_model(model, train_loader, val_loader, epochs, criterion, optimizer):\n",
    "    # Lists to store training and validation losses, and accuracies\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    # Loop over epochs\n",
    "    for epoch in range(epochs):\n",
    "        # Set the model to training mode\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        # Training loop\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "        # Calculate average training loss\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        # Calculate training accuracy\n",
    "        train_accuracy = correct_train / total_train\n",
    "        train_accuracies.append(train_accuracy)\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "\n",
    "        # Validation without gradient computation\n",
    "        with torch.no_grad():\n",
    "            for val_images, val_labels in val_loader:\n",
    "                val_images, val_labels = val_images.to(device), val_labels.to(device)\n",
    "                val_outputs = model(val_images)\n",
    "                val_loss = criterion(val_outputs, val_labels)\n",
    "                total_val_loss += val_loss.item()\n",
    "\n",
    "                _, predicted_val = torch.max(val_outputs.data, 1)\n",
    "                total_val += val_labels.size(0)\n",
    "                correct_val += (predicted_val == val_labels).sum().item()\n",
    "\n",
    "        # Calculate average validation loss\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        # Calculate validation accuracy\n",
    "        val_accuracy = correct_val / total_val\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        # Print progress every 10 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], '\n",
    "                f'Training Loss: {avg_train_loss:.4f}, Training Accuracy: {train_accuracy * 100:.2f}%, '\n",
    "                f'Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy * 100:.2f}%')\n",
    "\n",
    "    # Plotting the loss and accuracy over epochs\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accuracies, label='Training Accuracy')\n",
    "    plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return val_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a simple CNN\n",
    "Now, let's train a CNN on CIFAR 10. We will create a model and use the train and test function on to train and evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Hyperparameters and Training the Model\n",
    "\n",
    "# Number of training epochs\n",
    "epochs = 50\n",
    "\n",
    "# Create an instance of the SimpleCNN model and move it to the specified device (GPU if available)\n",
    "model = SimpleCNN().to(device)\n",
    "\n",
    "# Define the loss criterion (CrossEntropyLoss) and the optimizer (Adam) for training the model\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model using the defined training function\n",
    "val_losses_simple = train_model(model, train_loader, val_loader, epochs, criterion, optimizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results should show a clear overfitting with the validation loss increasing while the training loss keeps decreasing.\n",
    "* To address this, we will evaluate some regularization techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout\n",
    "\n",
    "Dropout is a regularization technique widely used in neural networks to mitigate overfitting. Proposed by Geoffrey Hinton and his collaborators, dropout involves randomly deactivating (dropping out) a fraction of neurons during training. This randomness prevents the network from relying too heavily on specific neurons, enhancing the model's generalization capabilities and reducing overfitting.\n",
    "\n",
    "Below you need to work on the code that defines a simple CNN model with dropout. Dropout layers are applied after each convolution layer to randomly deactivate neurons during training, enhancing the model's generalization capabilities. The dropout probability is a hyperparameter that controls the fraction of neurons dropped out during each forward pass.\n",
    "\n",
    "### Adding Dropout to a PyTorch CNN Model\n",
    "\n",
    "In this section, we will guide you through the process of adding dropout to a Convolutional Neural Network (CNN) implemented in PyTorch. By introducing dropout layers, you can enhance the model's generalization capabilities.\n",
    "\n",
    "### Task Overview\n",
    "The goal is to modify the CNN model (without dropout) defined above to incorporate dropout layers at specific points in the architecture. Here is a step-by-step instructions to guide you through this process.\n",
    "\n",
    "### Steps to Add Dropout\n",
    "Follow these steps to add dropout to your PyTorch CNN model:\n",
    "\n",
    "1. **Modify Model Class:**\n",
    "   Inside your CNN model class, add `nn.Dropout` layers at appropriate locations in the architecture. Commonly, dropout is added after activation functions or between fully connected layers. In this case, you need to add three dropout layers in the definition. In the forward function the dropout layers need to be applied after the two pooling layer, and after the activation function of the third convolution.\n",
    "\n",
    "2. **Adjust Dropout Probability:**\n",
    "   Set the dropout probability (`dropout_prob`) when initializing `nn.Dropout` layers. This probability determines the fraction of neurons to drop during training. In this case, the dorpout_prob is given as an argument to the constructor of the class.\n",
    "\n",
    "3. **Training and Evaluation Modes:**\n",
    "   Ensure that dropout is active during training and inactive during evaluation. PyTorch handles this automatically, but you can use `model.train()` and `model.eval()` methods to switch modes explicitly.\n",
    "\n",
    "4. **Experiment with Dropout Rate:**\n",
    "   Experiment with different dropout rates to find an optimal value for your specific model and dataset. Common values range from 0.2 to 0.5.\n",
    "\n",
    "### Example Code\n",
    "Here's a snippet illustrating how to add dropout to a simple CNN model in PyTorch:\n",
    "\n",
    "```python\n",
    "class SimpleCNN_dropout(nn.Module):\n",
    "    def __init__(self, dropout_prob=0.5):\n",
    "        super(SimpleCNN_dropout, self).__init__()\n",
    "        # ... (existing model layers)\n",
    "        self.dropout1 = nn.Dropout(dropout_prob)\n",
    "        # ... (more layers with dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout1(x)\n",
    "        # ... (continue with modified layers)\n",
    "\n",
    "```\n",
    "In the code below make sure you:\n",
    "* Add the three dropout layers with the given probability (dropout_prob)\n",
    "* Include the dropout in the forward function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a simple CNN model\n",
    "class SimpleCNN_dropout(nn.Module):\n",
    "    def __init__(self, dropout_prob=0.5):\n",
    "        super(SimpleCNN_dropout, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # Dropout applied after the first convolutional layer\n",
    "        self.dropout1 = #.....\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 64)\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        # Dropout applied after the first convolutional layer\n",
    "        x = #....\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)\n",
    "        x = x.view(-1, self.fc1.in_features)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model with Dropout\n",
    "Below we train a model with dropout, setting the rate to 0.5. \n",
    "\n",
    "* How do the results differ from the model without any regularization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "model_d = SimpleCNN_dropout(dropout_prob=0.5).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_d.parameters(), lr=0.001)\n",
    "val_losses_dropout = train_model(model_d, train_loader, val_loader, epochs, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using dropout should decrease the overfitting. Do you see the difference in the training progress when comparing it with the case where no dropout was used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation in PyTorch\n",
    "\n",
    "Data augmentation is a technique widely used in machine learning and computer vision to artificially increase the diversity of a dataset. The idea is to apply various transformations to the existing dataset, generating new, slightly altered versions of the original images. This helps improve the model's generalization and robustness by exposing it to a broader range of variations.\n",
    "\n",
    "### Benefits of Data Augmentation\n",
    "1. **Increased Diversity:**\n",
    "   Augmented data provides a more comprehensive representation of the real-world scenarios the model might encounter.\n",
    "\n",
    "2. **Reduced Overfitting:**\n",
    "   By training on augmented data, the model becomes less prone to overfitting, as it learns to recognize patterns under various conditions.\n",
    "\n",
    "3. **Improved Robustness:**\n",
    "   Exposure to diverse transformations enhances the model's ability to handle variations in lighting, orientation, and other factors.\n",
    "\n",
    "### Common Data Augmentation Techniques\n",
    "1. **Rotation:**\n",
    "   Randomly rotating images by a certain degree.\n",
    "\n",
    "2. **Horizontal Flip:**\n",
    "   Flipping images horizontally to simulate reflections.\n",
    "\n",
    "3. **Zooming:**\n",
    "   Randomly zooming in or out of images.\n",
    "\n",
    "4. **Crop and Resize:**\n",
    "   Randomly cropping and resizing images.\n",
    "\n",
    "5. **Brightness and Contrast Adjustment:**\n",
    "   Adjusting the brightness and contrast levels randomly.\n",
    "\n",
    "### Data Augmentation in PyTorch\n",
    "PyTorch provides convenient tools for implementing data augmentation through the `transforms` module. The `transforms` module allows you to chain multiple transformations together and apply them to your dataset during training.\n",
    "\n",
    "Here's a basic example of how to apply data augmentation using PyTorch:\n",
    "\n",
    "```python\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define a series of augmentation transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),  # Randomly flip images horizontally\n",
    "    transforms.RandomRotation(degrees=20),  # Randomly rotate images by a maximum of 20 degrees\n",
    "    transforms.RandomResizedCrop(32, scale=(0.8, 1.0), ratio=(0.9, 1.1)),  # Randomly crop and resize images\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),  # Adjust brightness, contrast, saturation, and hue randomly\n",
    "    transforms.ToTensor(),  # Convert the images to PyTorch tensors\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize the tensor values to a range of [0, 1]\n",
    "])\n",
    "\n",
    "\n",
    "# Apply the transformations to your dataset during training\n",
    "augmented_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task: Implementing Data Augmentation\n",
    "\n",
    "In this task, your goal is to enhance the existing Convolutional Neural Network (CNN) model for image classification on the CIFAR-10 dataset. You will implement two crucial techniques: dropout regularization and data augmentation.\n",
    "\n",
    "**Objective:** Increase the model's robustness by introducing variations in the training data.\n",
    "\n",
    "**Hints:**\n",
    "1. **Transformation Definition:** Create a set of data augmentation transformations using `transforms.Compose`.\n",
    "    - Include operations like random horizontal flip, random rotation, and color jittering.\n",
    "    - Do not forget that you need to transform images to tensors and normalize them using the ToTensor and Normalize functions. These must be applied after all the augmentations.\n",
    "\n",
    "2. **Data Loader Configuration:** Apply the defined transformations to the training data loader.\n",
    "    - Use the `get_data_loaders` function and pass the `transform_train` to the `transform_train` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of epochs and batch size\n",
    "epochs = 80\n",
    "\n",
    "# Create a CNN model with dropout\n",
    "model_d = SimpleCNN_dropout(dropout_prob=0.5).to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_d.parameters(), lr=0.001)\n",
    "\n",
    "# Define data augmentation transformations for training\n",
    "transform_train = #YOUR CODE HERE #\n",
    "\n",
    "# Create data loaders for training, validation, and testing using the defined transformations in transform_train\n",
    "train_loader, val_loader, test_loader, _ = # YOUR CODE HERE #\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the data with transformations\n",
    "Before training let's visualize some images from the training set with some random transformation using the visualization function and calling it with our new train DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_data(class_names, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these samples you should be able to see some of the trainsformations in action and realize how they make the task more complicated for the model, which is what helps it extract more general features and thus generalize better.\n",
    "\n",
    "Now ltet's train the model with data augmentation and dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "val_losses_data_aug = train_model(model_d, train_loader, val_loader, epochs, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the trainings\n",
    "Now that the three models have been trained, let's compare the progression of the validation loss for the three of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(val_losses_simple, label='No regularization')\n",
    "plt.plot(val_losses_dropout, label='Dropout')\n",
    "plt.plot(val_losses_data_aug, label='Data augmentation + Dropout')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model\n",
    "Here we create a function to test a model in a given test set.\n",
    "This code defines a testing function that evaluates the model on a test dataset, calculates accuracy, F1 score, and generates a confusion matrix. The model is set to evaluation mode to disable layers like dropout and ensure consistent predictions during testing. The results are printed, and the confusion matrix is visualized with class names. The function returns accuracy and F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Model\n",
    "def test_model(model, test_loader):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Initialize counters\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    # Disable gradient computation during testing\n",
    "    with torch.no_grad():\n",
    "        # Iterate through the test loader\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Get predictions\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            # Update counters\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Collect labels and predictions for further analysis\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = correct / total\n",
    "\n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(all_labels, all_predictions, average='macro')\n",
    "\n",
    "    # Build confusion matrix\n",
    "    confusion_mat = confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "    # Plot confusion matrix with class names\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(confusion_mat, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.show()\n",
    "\n",
    "    # Display test results\n",
    "    print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
    "    print(f\"F1 = {f1:.2f}\")\n",
    "\n",
    "    return accuracy, f1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "acc, f1 = test_model(model_d, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional tasks you can try:\n",
    "* Try different dropout probability to see how this affects the results.\n",
    "* Add other data augmentation transformations like RandomResizedCrop.\n",
    "* Implement L2 or weight decay regularization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
